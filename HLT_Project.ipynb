{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TdaWLsf9QULo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import transformers\n",
        "from transformers import AutoTokenizer, GPT2LMHeadModel\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8KEbC_w_-Zzg"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "o5OXuRul-dSa",
        "outputId": "f755e51b-0248-49e3-c4bf-7c7187d53e5a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3VpNhlys-yz_"
      },
      "outputs": [],
      "source": [
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "k4GQm-RBWmSq"
      },
      "outputs": [],
      "source": [
        "vocab = tokenizer.get_vocab()\n",
        "index_to_token = {x:y for (y, x) in vocab.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "g9yE0mA2bZZ0"
      },
      "outputs": [],
      "source": [
        "def encode(text):\n",
        "  inputs = tokenizer(text, return_tensors=\"pt\", verbose=True)\n",
        "  inputs = inputs.to(device)\n",
        "  outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
        "  logits = outputs.logits\n",
        "  logits = logits[0]\n",
        "\n",
        "  indices = [inputs['input_ids'][0][0].detach().item()]\n",
        "  for token, predicted in zip(inputs['input_ids'][0][1:], logits):\n",
        "    token = token.detach().item()\n",
        "    predictions = [(index, score) for index, score in enumerate(predicted.detach().tolist())]\n",
        "    predictions.sort(key=lambda x : (x[1], x[0]), reverse = True)\n",
        "    for i, p in enumerate(predictions):\n",
        "      if p[0] == token:\n",
        "        indices.append(i)\n",
        "  return indices\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RxTyan1hf4Qt"
      },
      "outputs": [],
      "source": [
        "def decode(indices):\n",
        "  input_ids = [indices[0]] + [0]*(len(indices)-1)\n",
        "  attention_mask = torch.tensor([[1]*len(indices)], device=device)\n",
        "  output = [index_to_token[indices[0]]]\n",
        "\n",
        "  for i, index in enumerate(indices[1:]):\n",
        "    ids = torch.tensor([input_ids], device=device)\n",
        "    outputs = model(input_ids=ids, attention_mask=attention_mask, labels=ids)\n",
        "    logits = outputs.logits\n",
        "\n",
        "    predicted = logits[0, i, :]\n",
        "    predictions = [(index, score) for index, score in enumerate(predicted.detach().tolist())]\n",
        "    predictions.sort(key=lambda x:(x[1], x[0]), reverse = True)\n",
        "    word_index = predictions[index][0]\n",
        "    word = tokenizer.decode([word_index])\n",
        "    output.append(word)\n",
        "    input_ids[i+1] = word_index\n",
        "  return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "lHjQvvgOTik8"
      },
      "outputs": [],
      "source": [
        "def single_encode(ids):\n",
        "  ids = torch.reshape(ids, (1, -1)).to(device)\n",
        "  with torch.no_grad():\n",
        "    outputs = model(input_ids= ids, attention_mask= torch.tensor([1]* len(ids)).to(device), labels=ids)\n",
        "    logits = outputs.logits\n",
        "    logits = logits[0]\n",
        "\n",
        "    indices = []\n",
        "    for token, predicted in zip(ids[0][1:], logits):\n",
        "      token = token.detach().item()\n",
        "      predictions = [(index, score) for index, score in enumerate(predicted.detach().tolist())]\n",
        "      predictions.sort(key=lambda x : (x[1], x[0]), reverse = True)\n",
        "      for i, p in enumerate(predictions):\n",
        "        if p[0] == token:\n",
        "          indices.append(i)\n",
        "  return indices\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "I1abCqagMxuz"
      },
      "outputs": [],
      "source": [
        "def window_encode(text, window_length, overlap):\n",
        "  inputs = tokenizer(text, return_tensors=\"pt\", verbose=True)\n",
        "  input_ids = inputs['input_ids'][0]\n",
        "  indices = [input_ids[0].detach().item()] + [0] * (len(input_ids)-1)\n",
        "  window_start = 0\n",
        "  window_end = window_length\n",
        "  prev_end = 1\n",
        "  while True:\n",
        "    window_end = min(window_end, len(input_ids))\n",
        "    cur_indices = single_encode(input_ids[window_start: window_end])\n",
        "    indices[prev_end:window_end] = cur_indices[-(window_end-prev_end):]\n",
        "    if window_end == len(input_ids):\n",
        "      break\n",
        "\n",
        "    prev_end = window_end\n",
        "\n",
        "    window_start = window_end-overlap\n",
        "    window_end = window_start+window_length\n",
        "\n",
        "  return indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "1GAtFCOThlEr"
      },
      "outputs": [],
      "source": [
        "def window_decode(indices, window_length, overlap):\n",
        "  input_ids = [indices[0]]\n",
        "  attention_mask = [1]\n",
        "  output = [index_to_token[indices[0]]]\n",
        "\n",
        "  for index in indices[1:]:\n",
        "    if len(input_ids) == window_length:\n",
        "      input_ids = input_ids[-overlap:]\n",
        "      attention_mask = [1]*overlap\n",
        "    inputs = {'input_ids': torch.tensor([input_ids]).to(device), 'attention_mask': torch.tensor([attention_mask]).to(device)}\n",
        "    inputs_class = transformers.tokenization_utils_base.BatchEncoding(inputs).to(device)\n",
        "    with torch.no_grad():\n",
        "      outputs = model(**inputs_class, labels=inputs[\"input_ids\"])\n",
        "      logits = outputs.logits\n",
        "\n",
        "      predicted = logits[0, -1, :]\n",
        "      predictions = [(index, score) for index, score in enumerate(predicted.detach().tolist())]\n",
        "      predictions.sort(key=lambda x:(x[1], x[0]), reverse = True)\n",
        "      word_index = predictions[index][0]\n",
        "      word = tokenizer.decode([word_index])\n",
        "      output.append(word)\n",
        "      input_ids.append(word_index)\n",
        "      attention_mask.append(1)\n",
        "  return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "IeNBTCo7kHJd"
      },
      "outputs": [],
      "source": [
        "from google.protobuf.internal import encoder, decoder\n",
        "\n",
        "def encode_indices(indices, encoded_filename):\n",
        "    with open(encoded_filename, 'wb') as file:\n",
        "        for number in indices:\n",
        "            encoded_bytes = encoder._VarintBytes(number)\n",
        "            file.write(encoded_bytes)\n",
        "\n",
        "def decode_indices(filename):\n",
        "    indices = []\n",
        "    with open(filename, 'rb') as file:\n",
        "        encoded_bytes = file.read()\n",
        "        position = 0\n",
        "        while position < len(encoded_bytes):\n",
        "            number, position = decoder._DecodeVarint(encoded_bytes, position)\n",
        "            indices.append(number)\n",
        "    return indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "QEUqQy2mkfQb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def compress_file(filename, output_file):\n",
        "  with open(filename, 'r', encoding='utf8') as file:\n",
        "    text = file.read()\n",
        "    # encode_indices(window_encode(text, 32, 4), output_file)\n",
        "    encode_indices(encode(text), output_file)\n",
        "\n",
        "    original_size = os.path.getsize(filename)\n",
        "    compressed_size = os.path.getsize(output_file)\n",
        "\n",
        "    print(\"Original size:\", original_size, \"bytes\")\n",
        "    print(\"Compressed size:\", compressed_size, \"bytes\")\n",
        "    print(\"Compression ratio:\", compressed_size/original_size)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "9IX3qxKIa4cq"
      },
      "outputs": [],
      "source": [
        "def decompress_file(compressed_file, output_file):\n",
        "  indices = decode_indices(compressed_file)\n",
        "  # text = ''.join(window_decode(indices, 32, 4))\n",
        "  text = ''.join(decode(indices))\n",
        "  with open(output_file, 'w', encoding='utf8') as file:\n",
        "    file.write(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDFP8HmybUJt",
        "outputId": "d879d69b-c310-4f35-e2db-e7a618f27b1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original size: 2591 bytes\n",
            "Compressed size: 711 bytes\n",
            "Compression ratio: 0.27441142416055575\n"
          ]
        }
      ],
      "source": [
        "compress_file('tolstoi.txt', 'tolstoi.bin')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "0SliDcbgcZDs"
      },
      "outputs": [],
      "source": [
        "decompress_file('tolstoi.bin', 'original.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rbyeH3QXmqpc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gzip\n",
        "def compress_gzip(filename):\n",
        "  compressed_filename = filename+'.gz'\n",
        "  with open(filename, 'rb') as file:\n",
        "        content = file.read()\n",
        "  with gzip.open(compressed_filename, 'wb') as compressed_file:\n",
        "        compressed_file.write(content)\n",
        "  original_size = os.path.getsize(filename)\n",
        "  print(original_size)\n",
        "  compressed_size = os.path.getsize(compressed_filename)\n",
        "  print(compressed_size)\n",
        "  compression_ratio = compressed_size/original_size\n",
        "  return (compressed_filename, compression_ratio)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1JW1QZjm32H",
        "outputId": "98a92c32-fabd-4014-b700-20cdbd51fd04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2591\n",
            "1376\n",
            "0.5310690852952528\n"
          ]
        }
      ],
      "source": [
        "file, ratio = compress_gzip('tolstoi.txt')\n",
        "print(ratio)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
